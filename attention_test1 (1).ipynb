{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"attention_test1 (1).ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [tensorflow]","language":"python","name":"Python [tensorflow]"}},"cells":[{"metadata":{"id":"_kLmj0-euBoU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","\n","import numpy as np\n","#np.random.seed(int(np.pi*10**5)) #\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, GRU, LSTM\n","from keras.layers import Input, TimeDistributed, Embedding, RepeatVector, Lambda, Bidirectional\n","from keras.layers import Flatten, Reshape, Permute, Activation\n","from keras.layers import Dot, Concatenate, Multiply\n","from keras.layers import merge\n","from keras.callbacks import EarlyStopping\n","from keras import backend as K\n","\n","from keras.preprocessing import sequence\n","from keras.preprocessing.text import Tokenizer\n","\n","#nltk.download()\n","\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import TweetTokenizer\n","from nltk.stem.wordnet import WordNetLemmatizer\n","\n","import sys  \n","\n","reload(sys)  \n","sys.setdefaultencoding('latin-1')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NHoIw4rTuTdc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once per notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Download a file based on its file ID.\n","#\n","# Search query reference:\n","# https://developers.google.com/drive/v2/web/search-parameters\n","listed = drive.ListFile({'q': \"title contains '.txt' and 'root' in parents\"}).GetList()\n","for file in listed:\n","  #py_file = list(file['title'])\n","  print('title {}, id {}'.format(file['title'], file['id']))\n","\n","\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"7QH9tqbAuBom","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ertGiWTWuBow","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["src_word_chunker = lambda sent: list(sent)\n","trg_word_chunker = lambda sent: list(sent)\n","\n","source, target = [], []\n","src_vocab, trg_vocab = set({}), set({})\n","src_max_len = 1\n","trg_max_len = 1\n","\n","file_id = '18BPogdqyco7sV8cdMtqg227ywKdYS7gG'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('fra_orig.txt') \n","\n","\n","with open('fra_orig.txt', 'r') as sythtree:\n","    for line in sythtree:\n","        src_sent_raw, trg_sent_raw = line.split('\\t')\n","        \n","        trg_sent_raw = trg_sent_raw.replace('\\n','')\n","        trg_sent_raw = 'BOS ' + str(trg_sent_raw) + ' EOS'\n","        \n","        src_words = word_tokenize(src_sent_raw)\n","        trg_words = word_tokenize(trg_sent_raw)\n","        \n","        # update vocabulary with new words\n","        src_vocab.update(src_words)\n","        trg_vocab.update(trg_words)\n","        \n","        #src_sent = src_word_chunker(src_sent_raw)\n","        #trg_sent = trg_word_chunker(trg_sent_raw)\n","\n","        # add to the list (chunked)\n","        source.append(src_sent_raw)\n","        target.append(trg_sent_raw)\n","        \n","        src_max_len   = src_max_len if src_max_len > len(src_words) else len(src_words)\n","        trg_max_len   = trg_max_len if trg_max_len > len(trg_words) else len(trg_words)\n","\n","print('source: ', source[0:5])\n","print('target:: ', target[0:5])\n","\n","# the first words is the padding sign:\n","src_vocab = list(src_vocab)\n","trg_vocab = ['BOS'] + list(trg_vocab) + ['EOS']\n","\n","src_vocab_size = len(src_vocab)\n","trg_vocab_size = len(trg_vocab)\n","\n","##print(src_vocab_size)\n","#print(trg_vocab_size)\n","\n","\n","## convert words to word_id \n","#source_sents = [ \n","#    [src_vocab.index(w) for w in sent]\n","#    for sent in source\n","#]\n","#\n","#target_sents = [ \n","#    [trg_vocab.index(w) for w in sent]\n","#    for sent in target\n","#]\n","\n","tok_src = Tokenizer(num_words=5000)\n","tok_trg = Tokenizer(num_words=5000)\n","\n","tok_src.fit_on_texts(source)\n","source_sents = tok_src.texts_to_sequences(source)\n","\n","tok_trg.fit_on_texts(target)\n","target_sents = tok_trg.texts_to_sequences(target)\n","\n","\n","print(\"source sents:: \", source_sents[0:7])\n","print(\"target sents:: \", target_sents[0:7])\n","\n","src_max_len = tok_src.num_words\n","trg_max_len = tok_trg.num_words\n","\n","print(\"source max size:\", src_max_len)\n","print(\"target max size:\", trg_max_len)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_lB-8CbDuBpC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","# fixed length of source and target inputs after padding\n","T_x = src_max_len\n","T_y = trg_max_len + 1\n","\n","# padded sentences\n","# https://keras.io/preprocessing/sequence/\n","source_pp = sequence.pad_sequences(source_sents, maxlen=T_x)\n","target_pp = sequence.pad_sequences(sequence.pad_sequences(target_sents, maxlen=T_y-1), maxlen=T_y)\n","trg_end_padding = np.pad(target_pp[:,1:], [(0,0), (0,1)], 'constant', constant_values=0)\n","\n","print(\"source pp:\", source_pp)\n","print(\"target pp:\", target_pp)\n","\n","print(\"source vocab size:\", src_vocab_size)\n","print(\"target vocab size:\", trg_vocab_size)\n","\n","print('source shape:', source_pp.shape)\n","print('target shape:', target_pp.shape)\n","\n","print(trg_end_padding)\n","\n","def one_hot_initializer(shape, dtype=None):\n","    \"\"\"Keras friendly initialization for one-hot encodedings as embedings\"\"\"\n","    output = K.eye(shape[0], dtype=dtype)\n","    output = K.concatenate([K.zeros_like(output[:1,:]), output[1:,:]], 0)\n","    output = K.concatenate([K.zeros_like(output[:,:1]), output[:,1:]], 1)\n","    return output\n","\n","def sequential_layer_composition(input_tensor, layers):\n","    \"\"\"This function takes a list of layers similar to Sequential but it is designed to work for Model in Keras\"\"\"\n","    if len(layers) > 1:\n","        return sequential_layer_composition(layers[0](input_tensor), layers[1:])\n","    else:\n","        return layers[0](input_tensor)\n","    \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VUJHx2r2uBpM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"294315f0-cf9e-4e03-c9b4-7e0c8e9b55b0"},"cell_type":"code","source":["\n","encoder_unit_size = 32\n","encoder_embedding_size = 8\n","#encoder_embedding_size = src_vocab_size\n","\n","print('T_x::', T_x)\n","print('T_y::', T_y)\n","\n","# the length of source and target inputs can be different but I chose the same max_len=10\n","src_input = Input(shape=(T_x,))\n","trg_input = Input(shape=(T_y,)) \n","\n","source_embeddings = Embedding(\n","    src_vocab_size,\n","    encoder_embedding_size,\n","    input_shape=(T_x,),\n","    #embeddings_initializer=one_hot_initializer,\n","    #trainable=False,\n",")\n","\n","print(source_embeddings)\n","\n","encoder_model = Sequential([\n","    source_embeddings, \n","    Bidirectional(LSTM(int(encoder_unit_size/2), return_sequences=True)),\n","    Bidirectional(LSTM(int(encoder_unit_size/2), return_sequences=True)),\n","])\n","\n","encoder_output = encoder_model(src_input)\n","\n","print(encoder_model.layers[0].input)\n","print(encoder_model.layers[0].output)\n","print(encoder_model.layers[1].output)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["T_x:: 5000\n","T_y:: 5001\n","<keras.layers.embeddings.Embedding object at 0x0000026707723B38>\n","Tensor(\"embedding_27_input:0\", shape=(?, 5000), dtype=float32)\n","Tensor(\"embedding_27/Gather:0\", shape=(?, 5000, 8), dtype=float32)\n","Tensor(\"bidirectional_29/concat:0\", shape=(?, ?, 32), dtype=float32)\n"],"name":"stdout"}]},{"metadata":{"id":"xuC1uIp0uBpW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"151b24e5-169d-424e-d6b6-7613da345bd9"},"cell_type":"code","source":["decoder_unit_size = 32\n","decoder_embedding_size = 8\n","#decoder_embedding_size = trg_vocab_size\n","\n","# Understanding the following code require both understanding the desgin, some math behind it, and Keras tricks.\n","m = T_x # source lenth\n","n = T_y # target lenth\n","d1 = encoder_unit_size\n","d2 = decoder_unit_size\n","\n","print('n, d:: ', n,d2)\n","# concatenate all H = (h_i) to all S = (s_j) ===> H_S = [s_(j-1) h_i] (S lag one phase behind)\n","S          = Input((n, d2,))\n","S_shift    = Lambda(lambda x: K.concatenate([K.zeros_like(K.expand_dims(x[:,0], 1)), x[:,:-1]], 1))(S)\n","S_flat     = Flatten()(S_shift)\n","S_flat_rep = RepeatVector(m)(S_flat)\n","S_rep_n    = Reshape((m, n, d2))(S_flat_rep)\n","# (m, n, d2,)\n","\n","print('m, d1:: ', m,d1)\n","\n","H            = Input((m, d1,))\n","H_flat       = Flatten()(H)\n","H_flat_rep   = RepeatVector(n)(H_flat)\n","H_flat_rep_  = Reshape((n, m, d1))(H_flat_rep)\n","H_rep_m      = Permute((2,1,3))(H_flat_rep_) \n","# (m, n, d1,)\n","\n","# concatenate everything with everything:\n","S_H_     = Concatenate(-1)([S_rep_n, H_rep_m]) \n","# (m, n, d1+d2)\n","S_H_flat = Flatten()(S_H_)\n","S_H      = Reshape((m*n, (d1+d2)))(S_H_flat) \n","# (m*n, (d1+d2),)\n","\n","# make the e_ji\n","E_T_1 = TimeDistributed(Dense(d1+d2, activation='tanh'))(S_H)\n","E_T_  = TimeDistributed(Dense(1, activation='linear'))(E_T_1)\n","E_T   = Reshape((m, n))(E_T_) \n","E     = Permute((2,1))(E_T) # E = {E_j} = {{ e_{ji} }} \n","# (n, m,)\n","\n","# the alignemtns\n","alpha = TimeDistributed(Activation('softmax'))(E) # alpha_j = softmax(E_j}\n","# (n, m,)\n","\n","C     = Dot((2,1))([alpha, H])\n","# (n, d1,)\n","\n","attention_model = Model([S, H], C)\n","\n","\n","target_embeddings = Embedding(\n","    trg_vocab_size,\n","    decoder_embedding_size,\n","    input_shape=(T_y,),\n","    #embeddings_initializer=one_hot_initializer,\n","    #trainable=False,\n",")\n","decoder_rnn = LSTM(decoder_unit_size, return_sequences=True, input_shape=(T_y, decoder_embedding_size+encoder_unit_size))\n","\n","decoder_model = Model(\n","    [src_input, trg_input],\n","    sequential_layer_composition(trg_input, [\n","        target_embeddings, \n","        decoder_rnn, \n","        lambda S: Concatenate(2)([S, attention_model([S, encoder_output])]), \n","        TimeDistributed(Dense(trg_vocab_size, activation='softmax')),\n","    ])\n",")\n","\n","\n","alignments_model = Model(\n","    [src_input, trg_input],\n","    sequential_layer_composition(trg_input, [\n","        target_embeddings,\n","        decoder_rnn, \n","        lambda x: Model([S, H], alpha)([x, encoder_output]),\n","    ])\n",")\n","\n","\n","print(decoder_model.summary())\n","print(alignments_model.summary())\n","\n","\n","# input of the encoder-decoder model is a list of two inputs: source, target\n","encoder_decoder = Model([src_input, trg_input], decoder_model([src_input, trg_input]))\n","\n","encoder_decoder.compile('adam', 'categorical_crossentropy')\n","\n","print(encoder_decoder.summary())\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["n, d::  5001 32\n","m, d1::  5000 32\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_54 (InputLayer)           (None, 5001)         0                                            \n","__________________________________________________________________________________________________\n","embedding_28 (Embedding)        (None, 5001, 8)      238784      input_54[0][0]                   \n","__________________________________________________________________________________________________\n","input_53 (InputLayer)           (None, 5000)         0                                            \n","__________________________________________________________________________________________________\n","lstm_39 (LSTM)                  (None, 5001, 32)     5248        embedding_28[0][0]               \n","__________________________________________________________________________________________________\n","sequential_15 (Sequential)      (None, 5000, 32)     132632      input_53[0][0]                   \n","__________________________________________________________________________________________________\n","model_41 (Model)                (None, 5001, 32)     4225        lstm_39[0][0]                    \n","                                                                 sequential_15[1][0]              \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 5001, 64)     0           lstm_39[0][0]                    \n","                                                                 model_41[1][0]                   \n","__________________________________________________________________________________________________\n","time_distributed_36 (TimeDistri (None, 5001, 29848)  1940120     concatenate_18[0][0]             \n","==================================================================================================\n","Total params: 2,321,009\n","Trainable params: 2,321,009\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_53 (InputLayer)           (None, 5000)         0                                            \n","__________________________________________________________________________________________________\n","input_54 (InputLayer)           (None, 5001)         0                                            \n","__________________________________________________________________________________________________\n","model_42 (Model)                (None, 5001, 29848)  2321009     input_53[0][0]                   \n","                                                                 input_54[0][0]                   \n","==================================================================================================\n","Total params: 2,321,009\n","Trainable params: 2,321,009\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"DbrVGz6KuBpi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"25e50628-a573-4ecc-cb6a-fad50c3edd5f"},"cell_type":"code","source":["print(trg_vocab_size)\n","print(trg_end_padding)\n","print(trg_end_padding.shape)\n","\n","y=np.eye(trg_max_len)[trg_end_padding]\n","print(y)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["29848\n","[[   0    0    0 ...    1    2    0]\n"," [   0    0    0 ...  119    2    0]\n"," [   0    0    0 ...  591    2    0]\n"," ...\n"," [   0    0    0 ...  289    2    0]\n"," [   0    0    0 ... 2223    2    0]\n"," [   0    0    0 ... 1026    2    0]]\n","(145438, 5001)\n"],"name":"stdout"},{"output_type":"error","ename":"MemoryError","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m<ipython-input-108-9d03499b12a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg_end_padding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg_max_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrg_end_padding\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mMemoryError\u001b[0m: "]}]},{"metadata":{"id":"3D1U74fTuBpw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"3533db5a-3414-41b3-a5d0-6bf97b5fff85"},"cell_type":"code","source":["encoder_decoder.fit(\n","    x          = [source_pp, target_pp],\n","    y          = np.eye(trg_max_len)[trg_end_padding],\n","    batch_size = 32,\n","    epochs     = 3,\n","    validation_split=0.2,\n","    callbacks=[EarlyStopping(patience=10)],\n",")"],"execution_count":0,"outputs":[{"output_type":"error","ename":"MemoryError","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m<ipython-input-107-fbcadaab35f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m encoder_decoder.fit(\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msource_pp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_pp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg_max_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrg_end_padding\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mMemoryError\u001b[0m: "]}]},{"metadata":{"id":"gLah3V4suBqE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}